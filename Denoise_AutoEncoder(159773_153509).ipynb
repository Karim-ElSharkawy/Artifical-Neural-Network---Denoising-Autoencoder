{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Denoise_AutoEncoder(159773-153509).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCJyoFULdf9h",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional AutoEncoder for Denoising BSDS500 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1dPsKfMkJYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Google Drive connectin\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZTsPNhAdf9j",
        "colab_type": "text"
      },
      "source": [
        "## Backend and Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okuRJVmzdf9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Dependencies\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JhEyNbwWdf9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "kerasBKED = os.environ[\"KERAS_BACKEND\"] \n",
        "print(kerasBKED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxuYgQDKdf91",
        "colab_type": "text"
      },
      "source": [
        "## Load BSDS500 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa3HqTRCdhhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download BSDS500 Dataset\n",
        "!wget http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY-7n4xOpXpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download testing image that will be used to compare.\n",
        "!wget https://paragonexpeditions.com/wp-content/uploads/2017/04/farming-with-local-quechua-community-sacred-valley-of-the-incas.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjia5p1XkAhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove extra folder\n",
        "!rm -r sample_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFqplxuYduZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unpack.\n",
        "!tar -xvf 'BSR_bsds500.tgz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuLE9268df93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting of Parameters\n",
        "batch_size = 16\n",
        "epochs = 100\n",
        "saveDir = \"drive/My Drive/Colab Notebooks/ANN_Result/\"\n",
        "if not os.path.isdir(saveDir):\n",
        "    os.makedirs(saveDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVr5kgsaxBQu",
        "colab_type": "text"
      },
      "source": [
        "Reading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxbk2QSodf98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import expand_dims\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Read Training Data from filepath\n",
        "files = glob.glob(\"BSR/BSDS500/data/images/train/*.jpg\")\n",
        "trainData = []\n",
        "# Loop over files in filepath and add them to list.\n",
        "for f1 in files:\n",
        "    # Read Image\n",
        "    img = cv2.imread(f1)\n",
        "    # Resize Image\n",
        "    img = cv2.resize(img, (400,400))\n",
        "    # Extract BGR content \n",
        "    b,g,r = cv2.split(img)\n",
        "    # Merge into an RGB image using the extracted content \n",
        "    img = cv2.merge([r,g,b]) \n",
        "    # Add image to List\n",
        "    trainData.append(img)\n",
        "    #Image Augmentation\n",
        "    imgArr = img_to_array(img)\n",
        "    samples = expand_dims(imgArr, 0)\n",
        "    datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "    it = datagen.flow(samples, batch_size=1)\n",
        "    # Generate a number of Images\n",
        "    for i in range(3):\n",
        "      batch = it.next()\n",
        "      image = batch[0].astype('uint8')\n",
        "      trainData.append(image)\n",
        "\n",
        "\n",
        "# Read Testing Data from filepath\n",
        "files = glob.glob(\"BSR/BSDS500/data/images/test/*.jpg\")\n",
        "testData = []\n",
        "# Loop over files in filepath and add them to list.\n",
        "for f1 in files:\n",
        "    # Read Image\n",
        "    img = cv2.imread(f1)\n",
        "    # Resize Image\n",
        "    img = cv2.resize(img, (400,400))\n",
        "    # Extract BGR content \n",
        "    b,g,r = cv2.split(img)\n",
        "    # Merge into an RGB image using the extracted content  \n",
        "    img = cv2.merge([r,g,b]) \n",
        "    # Add image to List\n",
        "    testData.append(img)\n",
        "    # Image Augmentation\n",
        "    imgArr = img_to_array(img)\n",
        "    samples = expand_dims(imgArr, 0)\n",
        "    datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "    it = datagen.flow(samples, batch_size=1)\n",
        "    # Generate a Number of Images\n",
        "    for i in range(3):\n",
        "      batch = it.next()\n",
        "      image = batch[0].astype('uint8')\n",
        "      testData.append(image)\n",
        "\n",
        "files = glob.glob(\"BSR/BSDS500/data/images/val/*.jpg\")\n",
        "# Loop over files in filepath and add them to list.\n",
        "for f1 in files:\n",
        "    # Read Image\n",
        "    img = cv2.imread(f1)\n",
        "    # Resize Image\n",
        "    img = cv2.resize(img, (400,400))\n",
        "    # Extract BGR content \n",
        "    b,g,r = cv2.split(img)\n",
        "    # Merge into an RGB image using the extracted content  \n",
        "    img = cv2.merge([r,g,b]) \n",
        "    # Add image to List\n",
        "    trainData.append(img)\n",
        "\n",
        "    imgArr = img_to_array(img)\n",
        "    samples = expand_dims(imgArr, 0)\n",
        "    datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "    it = datagen.flow(samples, batch_size=1)\n",
        "    for i in range(9):\n",
        "      batch = it.next()\n",
        "      image = batch[0].astype('uint8')\n",
        "      trainData.append(image)\n",
        "# Read a Test Image used for displaying.\n",
        "img = cv2.imread(\"farming-with-local-quechua-community-sacred-valley-of-the-incas.jpg\")\n",
        "img = cv2.resize(img, (400,400))\n",
        "b,g,r = cv2.split(img)\n",
        "img = cv2.merge([r,g,b])\n",
        "testData.append(img)\n",
        "\n",
        "# Change to Numpy Array   \n",
        "trainData = np.array(trainData)\n",
        "testData = np.array(testData)\n",
        "\n",
        "x_train = trainData\n",
        "x_test = testData\n",
        "\n",
        "# Shuffle Dataset after Augmentation\n",
        "np.random.shuffle(x_train)\n",
        "np.random.shuffle(x_test[:-2])\n",
        "\n",
        "#Display Shape\n",
        "print(\"x_train.shape: \" + str(x_train.shape))\n",
        "print(\"x_test.shape: \" + str(x_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB9HulTuzQyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display Sample from Train Set\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QngMpvjndf-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize data\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWJKMKE0df-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiSWIknTdf-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# divide x_test into validation and test\n",
        "x_val = x_test[:400]\n",
        "x_test = x_test[400:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koRbXEaCdf-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Shapes for Integrity check\n",
        "print(\"validation data: {0} \\ntest data: {1}\".format(x_val.shape, x_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm80xMz_df-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0].reshape(400, 400, 3))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyaHXp4Ydf-e",
        "colab_type": "text"
      },
      "source": [
        "## add noise to data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_oVaqnYdf-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding of noise to the np array of images using additive noise factoring and np normal\n",
        "noise_factor = 0.2\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
        "x_val_noisy = x_val + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_val.shape) \n",
        "\n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "x_val_noisy = np.clip(x_val_noisy, 0., 1.)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZOADjeKdf-j",
        "colab_type": "text"
      },
      "source": [
        "## show noisy images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCJZvcvLdf-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# definition to show original image and reconstructed image\n",
        "def showOrigDec(orig, noise, num=3):\n",
        "    import matplotlib.pyplot as plt\n",
        "    n = num\n",
        "    plt.figure(figsize=(20, 4))\n",
        "\n",
        "    for i in range(n):\n",
        "        # display original\n",
        "        ax = plt.subplot(2, n, i+1)\n",
        "        plt.imshow(orig[i].reshape(400, 400, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        \n",
        "        # display original\n",
        "        ax = plt.subplot(2, n, i +1 + n)\n",
        "        plt.imshow(noise[i].reshape(400, 400, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIae5DFadf-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "showOrigDec(x_train, x_train_noisy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXnTN8BFdf-7",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional AutoEncoder for denoising"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIyIO9O6df-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(400, 400, 3))\n",
        "#ENCODE\n",
        "x = Conv2D(100, (3, 3), padding='same')(input_img)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(50, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "#CODE Representation\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "#DECODE\n",
        "x = Conv2D(50, (3, 3), padding='same')(encoded)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(100, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(3, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "decoded = Activation('sigmoid')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5kxFSAsdf-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import metrics\n",
        "# Start Model and set Optimizer, loss function and metrics.\n",
        "model = Model(input_img, decoded)\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['accuracy', metrics.mae, metrics.mse])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EgbpZlndf_C",
        "colab_type": "text"
      },
      "source": [
        "## Train AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFgDxnDQPbak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIjs78k2S2RE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clear any logs from previous runs\n",
        "# !rm -rf ./my_log_dir/\n",
        "#import os\n",
        "#os.rmdir(\"./my_log_dir/\")\n",
        "# shutil.rmtree('./my_log_dir/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYlGzovGdf_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load pretrained weights\n",
        "# model.load_weights(saveDir + 'AutoEncoder.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQE6P9VMdf_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Callbakc functions that will be called on epoch.\n",
        "from keras.callbacks import TensorBoard\n",
        "es_cb = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
        "chkpt = saveDir + 'AutoEncoder.hdf5'\n",
        "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "tfBoard = TensorBoard(\n",
        "        log_dir=\"my_log_dir\",\n",
        "        histogram_freq=1,\n",
        "\n",
        "    )\n",
        "reduceLR = keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.01,\n",
        "        patience=10,\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Kuyy4e4adf_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Start Fitting the NN using the settings provided above.\n",
        "history = model.fit(x_train_noisy, x_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_val_noisy, x_val),\n",
        "                    callbacks=[es_cb, cp_cb, tfBoard, reduceLR],\n",
        "                    shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxrfJzZMPfyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display Tensorboard.\n",
        "#!kill 507 \n",
        "%tensorboard --logdir=my_log_dir --host localhost --port=8005"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrckX9nK_WwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "# Display Model Structure\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpJCob1Udf_N",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEXv4fSVdf_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(x_test_noisy, x_test, verbose=1)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trImEV41df_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test Image Arrays.\n",
        "c10test = model.predict(x_test_noisy)\n",
        "c10val = model.predict(x_val_noisy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXtbDfi_df_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"test score: {0}\\nval score: {1}\".format(np.average(c10test), np.average(c10val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pvVDphhHdf_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# definition to show original image and reconstructed image\n",
        "def showOrigDec(orig, noise, denoise, num=10):\n",
        "    import matplotlib.pyplot as plt\n",
        "    n = num\n",
        "    plt.figure(figsize=(20, 4))\n",
        "\n",
        "    for i in range(n):\n",
        "        # display original\n",
        "        ax = plt.subplot(3, n, i+1)\n",
        "        plt.imshow(orig[i].reshape(400, 400, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # display noisy image\n",
        "        ax = plt.subplot(3, n, i +1 + n)\n",
        "        plt.imshow(noise[i].reshape(400, 400, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        \n",
        "        # display denoised image\n",
        "        ax = plt.subplot(3, n, i +1 + n + n)\n",
        "        plt.imshow(denoise[i].reshape(400, 400, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvJmwqUVdf_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display a number of Images (default=10)\n",
        "showOrigDec(x_test, x_test_noisy, c10test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhZ4mg4FUTKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c10test = model.predict(x_test_noisy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgblLqiEdf_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "imgNum = -1\n",
        "f, axarr = plt.subplots(1, 3, figsize=(26, 6))\n",
        "axarr[0].imshow(x_test[imgNum], aspect='auto')\n",
        "axarr[0].get_xaxis().set_visible(False)\n",
        "axarr[0].get_yaxis().set_visible(False)\n",
        "axarr[1].imshow(x_test_noisy[imgNum], aspect='auto')\n",
        "axarr[1].get_xaxis().set_visible(False)\n",
        "axarr[1].get_yaxis().set_visible(False)\n",
        "axarr[2].imshow(c10test[imgNum], aspect='auto')\n",
        "axarr[2].get_xaxis().set_visible(False)\n",
        "axarr[2].get_yaxis().set_visible(False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}